{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "Clase - Laboratorio - PySpark SQL - Parte 1",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "**Spark SQL trabaja con DataFrames**. Un DataFrame, como ya lo hemos comentado es una **representación relacional de los datos**. Proporciona funciones con capacidades similares a SQL. Además, permite escribir **consultas tipo SQL** para nuestro análisis de datos.",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f8276f39-ebfc-4f21-9ad1-399f84e5716c",
          "showTitle": false,
          "title": ""
        },
        "id": "2RJTjITkFCQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Creacion de un df desde 0",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ccf9553d-7368-480c-bc9e-1f369253c2b2",
          "showTitle": false,
          "title": ""
        },
        "id": "LlH6rSFoFCQK"
      }
    },
    {
      "cell_type": "code",
      "source": "emp = [(1, \"AAAAA\", \"dept1\", 1000),\n    (2, \"BBBBB\", \"dept1\", 1100),\n    (3, \"CCCCC\", \"dept1\", 2000),\n    (4, \"DDDDD\", \"dept1\", 3500),\n    (5, \"EEEEE\", \"dept2\", 8000),\n    (6, \"FFFFF\", \"dept2\", 5200),\n    (7, \"GGGGG\", \"dept3\", 3100),\n    (8, \"HHHHH\", \"dept3\", 6700),\n    (9, \"IIIII\", \"dept3\", 6500),\n    (10, \"JJJJJ\", \"dept4\", 5400)]\n\ndept = [(\"dept1\", \"Department - 1\"),\n        (\"dept2\", \"Department - 2\"),\n        (\"dept3\", \"Department - 3\"),\n        (\"dept4\", \"Department - 4\")\n       ]\n\ndfemp = spark.createDataFrame(emp, [\"id\", \"name\", \"dept\", \"salary\"])\n\ndeptdf = spark.createDataFrame(dept, [\"id\", \"name\"])",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5d8c78ff-1d0b-4a0f-8d6a-de7fadffa2ae",
          "showTitle": false,
          "title": ""
        },
        "id": "90Om8bW-FCQL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dfemp.show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5f7eb607-0e60-40df-9bbd-43f314e3f73a",
          "showTitle": false,
          "title": ""
        },
        "id": "eIrE4w6HFCQM",
        "outputId": "9e4fd174-24a5-4b3e-aa9e-4a43d15a68e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+\n| id| name| dept|salary|\n+---+-----+-----+------+\n|  1|AAAAA|dept1|  1000|\n|  2|BBBBB|dept1|  1100|\n|  3|CCCCC|dept1|  2000|\n|  4|DDDDD|dept1|  3500|\n|  5|EEEEE|dept2|  8000|\n|  6|FFFFF|dept2|  5200|\n|  7|GGGGG|dept3|  3100|\n|  8|HHHHH|dept3|  6700|\n|  9|IIIII|dept3|  6500|\n| 10|JJJJJ|dept4|  5400|\n+---+-----+-----+------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "deptdf.show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "82186e02-ed37-49be-a2e4-0354e39f69e2",
          "showTitle": false,
          "title": ""
        },
        "id": "owaw84fxFCQN",
        "outputId": "b2505910-eb49-4628-d476-f53ed97de7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-----+--------------+\n|   id|          name|\n+-----+--------------+\n|dept1|Department - 1|\n|dept2|Department - 2|\n|dept3|Department - 3|\n|dept4|Department - 4|\n+-----+--------------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Operaciones básicas en DataFrames\n\nPodemos aplicar las transformaciones que ya hemos visto en la seccion de RDDs, por ejemplo:",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "919e9be1-ff40-4a43-a804-eb8d5e03febe",
          "showTitle": false,
          "title": ""
        },
        "id": "EVZKDTK7FCQO"
      }
    },
    {
      "cell_type": "code",
      "source": "dfemp.count()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d9995564-d907-48f4-a275-a0fad5ffc676",
          "showTitle": false,
          "title": ""
        },
        "id": "ZXuEgMQbFCQO",
        "outputId": "150d6bdb-dfa9-4d81-a323-887543abc677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Out[34]: 10"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dfemp.printSchema()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "be336061-0c5d-4427-9c6f-30975fed0b8f",
          "showTitle": false,
          "title": ""
        },
        "id": "TRy4nrbCFCQO",
        "outputId": "28c2fb04-9944-4515-fc37-53c3a3a1800e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- salary: long (nullable = true)\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dfemp.select(\"id\", \"name\").show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3fd3b0f9-2601-474f-a323-0d85b53fc5de",
          "showTitle": false,
          "title": ""
        },
        "id": "9S_66yomFCQP",
        "outputId": "1de4444f-57e6-42a2-d276-b31ac9476120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+\n| id| name|\n+---+-----+\n|  1|AAAAA|\n|  2|BBBBB|\n|  3|CCCCC|\n|  4|DDDDD|\n|  5|EEEEE|\n|  6|FFFFF|\n|  7|GGGGG|\n|  8|HHHHH|\n|  9|IIIII|\n| 10|JJJJJ|\n+---+-----+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Ejemplo avanzado de: filter\n\n* Filtrar las filas según alguna condición.\n* Intentemos encontrar las filas con id = 1.\n* Hay diferentes formas de especificar la condición.",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2cf9a785-381b-4567-a97e-98cfdddee583",
          "showTitle": false,
          "title": ""
        },
        "id": "wYHiGY4tFCQP"
      }
    },
    {
      "cell_type": "code",
      "source": "dfemp.filter(dfemp[\"id\"] == 1).show()\ndfemp.filter(dfemp.id == 1).show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "96c6265d-5b9e-4928-a97c-896c8c58856c",
          "showTitle": false,
          "title": ""
        },
        "id": "hDnjmWboFCQP",
        "outputId": "f998648b-b6d6-40c2-bcac-749d5eaa8016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+\n| id| name| dept|salary|\n+---+-----+-----+------+\n|  1|AAAAA|dept1|  1000|\n+---+-----+-----+------+\n\n+---+-----+-----+------+\n| id| name| dept|salary|\n+---+-----+-----+------+\n|  1|AAAAA|dept1|  1000|\n+---+-----+-----+------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql.functions import col\n\ndfemp.filter(col(\"id\") == 1).show()\ndfemp.filter(\"id = 1\").show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "014b4e9b-08aa-433c-be74-a6ba431293c6",
          "showTitle": false,
          "title": ""
        },
        "id": "c-2FyTpHFCQQ",
        "outputId": "8301ba40-5ce7-4c69-dd14-423a28c968b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+\n| id| name| dept|salary|\n+---+-----+-----+------+\n|  1|AAAAA|dept1|  1000|\n+---+-----+-----+------+\n\n+---+-----+-----+------+\n| id| name| dept|salary|\n+---+-----+-----+------+\n|  1|AAAAA|dept1|  1000|\n+---+-----+-----+------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Funcion: drop\n* Elimina una columna en particular",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8e65f304-aab9-4acc-93cb-9deed0e04075",
          "showTitle": false,
          "title": ""
        },
        "id": "DJSP03rAFCQQ"
      }
    },
    {
      "cell_type": "code",
      "source": "newdf = dfemp.drop(\"id\")\nnewdf.show(2)",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a55a0bcc-07c6-4281-8b39-077207b79dbf",
          "showTitle": false,
          "title": ""
        },
        "id": "QmbHEiG1FCQQ",
        "outputId": "1cb92df3-1e8a-487a-a348-dcdad53ceffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-----+-----+------+\n| name| dept|salary|\n+-----+-----+------+\n|AAAAA|dept1|  1000|\n|BBBBB|dept1|  1100|\n+-----+-----+------+\nonly showing top 2 rows\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Funcion: withColumn\n* Podemos usar la función \"withColumn\" para derivar la columna en función de las columnas existentes.",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8fd35de5-058f-4c33-9921-099de3baf942",
          "showTitle": false,
          "title": ""
        },
        "id": "Lp8MmGX7FCQQ"
      }
    },
    {
      "cell_type": "code",
      "source": "dfemp.withColumn(\"bonus\", col(\"salary\") * .1).show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f45c66f9-cf12-435b-b38f-df2f941d2283",
          "showTitle": false,
          "title": ""
        },
        "id": "4uRlk4FfFCQQ",
        "outputId": "cfaf0115-5344-4c11-de7b-488164e6bb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+-----+\n| id| name| dept|salary|bonus|\n+---+-----+-----+------+-----+\n|  1|AAAAA|dept1|  1000|100.0|\n|  2|BBBBB|dept1|  1100|110.0|\n|  3|CCCCC|dept1|  2000|200.0|\n|  4|DDDDD|dept1|  3500|350.0|\n|  5|EEEEE|dept2|  8000|800.0|\n|  6|FFFFF|dept2|  5200|520.0|\n|  7|GGGGG|dept3|  3100|310.0|\n|  8|HHHHH|dept3|  6700|670.0|\n|  9|IIIII|dept3|  6500|650.0|\n| 10|JJJJJ|dept4|  5400|540.0|\n+---+-----+-----+------+-----+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Ejemplo de agregacion:\n* Podemos usar la función groupBy para agrupar los datos y luego usar la función \"agg\" para realizar la agregación de datos agrupados.",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a6e0a420-796a-4be0-b97d-758dcb001282",
          "showTitle": false,
          "title": ""
        },
        "id": "OKs0NXARFCQQ"
      }
    },
    {
      "cell_type": "code",
      "source": "from pyspark.sql import functions as f\n\n(dfemp.groupBy(\"dept\")\n    .agg(\n        f.count(\"salary\").alias(\"conteo\"),\n        f.sum(\"salary\").alias(\"suma\"),\n        f.max(\"salary\").alias(\"maximo\"),\n        f.min(\"salary\").alias(\"minimo\"),\n        f.avg(\"salary\").alias(\"promedio\"))\n    .show()\n)",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e39e12da-62df-4ebc-9924-4ccd9b4334f7",
          "showTitle": false,
          "title": ""
        },
        "id": "6eGQiFXiFCQR",
        "outputId": "b448c7f6-bada-4d90-9743-ae5b7d00c5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-----+------+-----+------+------+-----------------+\n| dept|conteo| suma|maximo|minimo|         promedio|\n+-----+------+-----+------+------+-----------------+\n|dept1|     4| 7600|  3500|  1000|           1900.0|\n|dept2|     2|13200|  8000|  5200|           6600.0|\n|dept3|     3|16300|  6700|  3100|5433.333333333333|\n|dept4|     1| 5400|  5400|  5400|           5400.0|\n+-----+------+-----+------+------+-----------------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Por ultimo, tambien podemos hacer joins, como en SQL",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e2d35e94-da8c-4729-a403-ab5fdf540cb5",
          "showTitle": false,
          "title": ""
        },
        "id": "tSt7m29qFCQR"
      }
    },
    {
      "cell_type": "code",
      "source": "# Inner JOIN.\ndfemp.join(deptdf, dfemp[\"dept\"] == deptdf[\"id\"]).show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ccbfc359-72a3-4012-adff-577e41502168",
          "showTitle": false,
          "title": ""
        },
        "id": "KTm6sdR2FCQR",
        "outputId": "cf5508e1-f3d9-4448-d4b1-decb0e760c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+-----+--------------+\n| id| name| dept|salary|   id|          name|\n+---+-----+-----+------+-----+--------------+\n|  1|AAAAA|dept1|  1000|dept1|Department - 1|\n|  2|BBBBB|dept1|  1100|dept1|Department - 1|\n|  3|CCCCC|dept1|  2000|dept1|Department - 1|\n|  4|DDDDD|dept1|  3500|dept1|Department - 1|\n|  5|EEEEE|dept2|  8000|dept2|Department - 2|\n|  6|FFFFF|dept2|  5200|dept2|Department - 2|\n|  7|GGGGG|dept3|  3100|dept3|Department - 3|\n|  8|HHHHH|dept3|  6700|dept3|Department - 3|\n|  9|IIIII|dept3|  6500|dept3|Department - 3|\n| 10|JJJJJ|dept4|  5400|dept4|Department - 4|\n+---+-----+-----+------+-----+--------------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Left Outer Join",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4ef13620-2801-4a10-9b30-cce026545201",
          "showTitle": false,
          "title": ""
        },
        "id": "ZY_sLzKxFCQR"
      }
    },
    {
      "cell_type": "code",
      "source": "dfemp.join(deptdf, dfemp[\"dept\"] == deptdf[\"id\"], \"left_outer\").show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1875bc64-e64e-42f6-ac71-83c4fcd5ffda",
          "showTitle": false,
          "title": ""
        },
        "id": "YJNMkHgvFCQR",
        "outputId": "89bb0517-ecfc-46ae-d798-ca25c4f4e645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+-----+--------------+\n| id| name| dept|salary|   id|          name|\n+---+-----+-----+------+-----+--------------+\n|  1|AAAAA|dept1|  1000|dept1|Department - 1|\n|  2|BBBBB|dept1|  1100|dept1|Department - 1|\n|  3|CCCCC|dept1|  2000|dept1|Department - 1|\n|  4|DDDDD|dept1|  3500|dept1|Department - 1|\n|  5|EEEEE|dept2|  8000|dept2|Department - 2|\n|  6|FFFFF|dept2|  5200|dept2|Department - 2|\n|  7|GGGGG|dept3|  3100|dept3|Department - 3|\n|  8|HHHHH|dept3|  6700|dept3|Department - 3|\n|  9|IIIII|dept3|  6500|dept3|Department - 3|\n| 10|JJJJJ|dept4|  5400|dept4|Department - 4|\n+---+-----+-----+------+-----+--------------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Right Outer Join",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f606495f-831b-4671-ab7e-e0015a7b870e",
          "showTitle": false,
          "title": ""
        },
        "id": "VM-AfBZ-FCQR"
      }
    },
    {
      "cell_type": "code",
      "source": "dfemp.join(deptdf, dfemp[\"dept\"] == deptdf[\"id\"], \"right_outer\").show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "699de0d9-0219-41a9-9028-f732dfca5031",
          "showTitle": false,
          "title": ""
        },
        "id": "zsSadcVBFCQR",
        "outputId": "de8b1a02-4848-4ef6-b9b7-e46f9589b93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+-----+--------------+\n| id| name| dept|salary|   id|          name|\n+---+-----+-----+------+-----+--------------+\n|  4|DDDDD|dept1|  3500|dept1|Department - 1|\n|  3|CCCCC|dept1|  2000|dept1|Department - 1|\n|  2|BBBBB|dept1|  1100|dept1|Department - 1|\n|  1|AAAAA|dept1|  1000|dept1|Department - 1|\n|  6|FFFFF|dept2|  5200|dept2|Department - 2|\n|  5|EEEEE|dept2|  8000|dept2|Department - 2|\n|  9|IIIII|dept3|  6500|dept3|Department - 3|\n|  8|HHHHH|dept3|  6700|dept3|Department - 3|\n|  7|GGGGG|dept3|  3100|dept3|Department - 3|\n| 10|JJJJJ|dept4|  5400|dept4|Department - 4|\n+---+-----+-----+------+-----+--------------+\n\n"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Full Outer Join",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "206e0307-2d6e-4e52-961b-69b9bdb2560b",
          "showTitle": false,
          "title": ""
        },
        "id": "wQlri817FCQR"
      }
    },
    {
      "cell_type": "code",
      "source": "dfemp.join(deptdf, dfemp[\"dept\"] == deptdf[\"id\"], \"outer\").show()",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fb3875a9-4274-40a5-be8c-81dd4dc70f2e",
          "showTitle": false,
          "title": ""
        },
        "id": "R_Yqy3JXFCQR",
        "outputId": "5fef3045-c271-4df1-fb26-09146736d78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+---+-----+-----+------+-----+--------------+\n| id| name| dept|salary|   id|          name|\n+---+-----+-----+------+-----+--------------+\n|  1|AAAAA|dept1|  1000|dept1|Department - 1|\n|  2|BBBBB|dept1|  1100|dept1|Department - 1|\n|  3|CCCCC|dept1|  2000|dept1|Department - 1|\n|  4|DDDDD|dept1|  3500|dept1|Department - 1|\n|  5|EEEEE|dept2|  8000|dept2|Department - 2|\n|  6|FFFFF|dept2|  5200|dept2|Department - 2|\n|  7|GGGGG|dept3|  3100|dept3|Department - 3|\n|  8|HHHHH|dept3|  6700|dept3|Department - 3|\n|  9|IIIII|dept3|  6500|dept3|Department - 3|\n| 10|JJJJJ|dept4|  5400|dept4|Department - 4|\n+---+-----+-----+------+-----+--------------+\n\n"
        }
      ],
      "execution_count": null
    }
  ]
}